{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ Before you start ⚠️\n",
    "\n",
    "_Duplicate this Jupyter Notebook in your `week-03` folder (right-click -> Duplicate) and then add your last name to the beginning of it (ie. `hw-03-blevins.ipynb` - otherwise you risk having all your work overwritten when you try to sync your GitHub repository with your instructor's repository._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ _No, seriously: check the name of this file. Is it the copy you made? (ie. `hw-03-blevins.ipynb`). If so, you can proceed_ ⚠️\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "Student Name: Rayce Loveland\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to analyze several historical documents in this homework. In keeping with the theme of our first unit for the semester, **Slavery and Data**, I've chosen two 19th-century narratives written by formerly enslaved people: [Sojourner Truth](https://archive.org/details/narrativeofsojou1850gilb) and [Henry \"Box\" Brown](https://archive.org/details/narrativeofhenry00brow).\n",
    "\n",
    "You should have the following files:\n",
    "\n",
    "- `hw-03-yourlastname.ipynb` (your working version Jupyter Notebook)\n",
    "- `truth.txt` (Sojourner Truth's narrative)\n",
    "- `brown.txt` (Henry Brown's narrative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `open()` and `read()` functions to get the content of each of these files into Python, assigning them the corresponding variable names of `truth_fulltext` and `brown_fulltext`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "truth_fulltext = open(\"truth.txt\", encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_fulltext = open(\"brown.txt\", encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next two code cells, write print() statements that:\n",
    "\n",
    "- Print the **first 500 characters** of Truth's narrative.\n",
    "- Print characters **5000 to 6000** of Brown's narrative.\n",
    "\n",
    "Hint: use the index and slice approaches for strings: <https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/06-String-Methods.html>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NARRATIVE OF SOJOURNER TRUTH\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HER BIRTH AND PARENTAGE.\n",
      "\n",
      "\n",
      "THE subject of this biography, SOJOURNER TRUTH, as she now calls\n",
      "herself-but whose name, originally, was Isabella-was born, as near as\n",
      "she can now calculate, between the years 1797 and 1800.  She was the\n",
      "daughter of James and Betsey, slaves of one Colonel Ardinburgh, Hurley,\n",
      "Ulster County, New York.\n",
      "\n",
      "Colonel  Ardinburgh belonged to that class of people called Low Dutch.\n",
      "\n",
      "\n",
      "Of her first master, she can give no account, as she must have be\n"
     ]
    }
   ],
   "source": [
    "truth=truth_fulltext[0:500]\n",
    "print(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of pity, indignation and\n",
      "horror.\n",
      "\n",
      "I first drew the breath of life in Louisa County, Va., forty-five miles\n",
      "from the city of Richmond, in the year 1816. I was born a slave. Not\n",
      "because at the moment of my birth an angel stood by, and declared that\n",
      "such was the will of God concerning me; although in a country whose most\n",
      "honored writings declare that all men have a right to liberty, given\n",
      "them by their Creator, it seems strange that I, or any of my brethren,\n",
      "could have been born without this inalienable right, unless God had thus\n",
      "signified his departure from his usual rule, as described by our\n",
      "fathers. Not, I say, on account of God’s willing it to be so, was I born\n",
      "a slave, but for the reason that nearly all the people of this country\n",
      "are united in legislating against heaven, and have contrived to vote\n",
      "down our heavenly father’s rules, and to substitute for them, that cruel\n",
      "law which binds the chains of slavery upon one sixth part of the\n",
      "inhabitants of this land. I was born a slave! and wh\n"
     ]
    }
   ],
   "source": [
    "brown=brown_fulltext [5000:6000]\n",
    "print(brown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell complete the following:\n",
    "\n",
    "- Look at the printed out \"slice\" of Brown's narrative. Make a new variable and assign it a value of **Brown's birth year.**\n",
    "- Make a new variable and assign it a value of: **how old Henry Brown would have been in the year 1860.**\n",
    "- Write a **print statement** using your new variable that says how old Henry Brown would have been in 1860.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1816\n"
     ]
    }
   ],
   "source": [
    "brown_birth_year=1816\n",
    "print(brown_birth_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "brown_age_1860 = 1860 - brown_birth_year\n",
    "print(brown_age_1860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henry Brown would have been 44 years old in 1860.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Henry Brown would have been {brown_age_1860} years old in 1860.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to compare how long each narrative is measured by the number of lines in each text. First, use the `split()` function for each narrative to break it apart by each new line. The new line character is `\\n`. Make two new variables storing a list of the broken apart text: `truth_lines` and `brown_lines`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'brown_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m brown_lines \u001b[38;5;241m=\u001b[39m brown_text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m truth_lines \u001b[38;5;241m=\u001b[39m truth_text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of lines in Brown\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms narrative: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(brown_lines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'brown_text' is not defined"
     ]
    }
   ],
   "source": [
    "brown_lines = brown_text.split('\\n')\n",
    "truth_lines = truth_text.split('\\n')\n",
    "print(f\"Number of lines in Brown's narrative: {len(brown_lines)}\")\n",
    "print(f\"Number of lines in Truth's narrative: {len(truth_lines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which narrative has more lines? You can calculate how many lines are in each narrative through the `len()` function which will calculate the **length** of each list of lines you made in the previous section.\n",
    "\n",
    "- Write two print() statements to show **how many lines are in each narrative**.\n",
    "- Add a third print() statement that calculates **the difference between these two narratives measured by their number of lines**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_line_count = len(brown_lines)\n",
    "truth_line_count = len(truth_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of lines in Brown's narrative is {brown_line_count}\")\n",
    "print(f\"The number of lines in Truth's narrative is {truth_line_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_difference = abs(brown_line_count - truth_line_count)\n",
    "print(f\"The difference in the number of lines between the two narratives is {line_difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the `len()` and `comparison` functions with an `if statement` to print either `Sojourner Truth's narrative has more lines` or `Henry Brown's narrative has more lines` based on which has more lines.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if brown_line_count > truth_line_count:\n",
    "    print(\"Henry Brown's narrative has more lines.\")\n",
    "else:\n",
    "    print(\"Sojourner Truth's narrative has more lines.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Word Frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the code below from Melanie Walsh's \"Anatomy of a Python Script\" that she used to calculate the most frequently occurring words in a novel \"The Yellow Wallpapper.\" You are going to use this code as a starting point but change it to apply this same approach to the two texts we've been working with. Your goal: **compare the most frequently occuring words in both Truth's narrative and Brown's narrative.**\n",
    "\n",
    "Note: don't edit Walsh's code cell directly. Instead, copy and paste the code into **the two empty code cells below it** that you can then edit. If you accidentally overwrite it and need to find the original, you can [copy it from the original tutorial.](https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/03-Anatomy-Python-Script.html)\n",
    "\n",
    "Adjustments you'll need to make to Walsh's code:\n",
    "\n",
    "- Open the right .txt file.\n",
    "- Find the most frequent **20 words** instead of 40 words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Walsh's Code - copy this into a new code cell\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def split_into_words(any_chunk_of_text):\n",
    "    lowercase_text = any_chunk_of_text.lower()\n",
    "    split_words = re.split(r\"\\W+\", lowercase_text)\n",
    "    return split_words\n",
    "\n",
    "filepath_of_text = \"The-Yellow-Wallpaper_Charlotte-Perkins-Gilman.txt\"\n",
    "number_of_desired_words = 40\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp', 'would', 'one']\n",
    "\n",
    "full_text = open(filepath_of_text, encoding=\"utf-8\").read()\n",
    "\n",
    "all_the_words = split_into_words(full_text)\n",
    "meaningful_words = [word for word in all_the_words if word not in stopwords]\n",
    "meaningful_words_tally = Counter(meaningful_words)\n",
    "most_frequent_meaningful_words = meaningful_words_tally.most_common(number_of_desired_words)\n",
    "\n",
    "most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def split_into_words(any_chunk_of_text):\n",
    "    lowercase_text = any_chunk_of_text.lower()\n",
    "    split_words = re.split(\"\\W+\", lowercase_text)\n",
    "    return split_words\n",
    "\n",
    "filepath_of_text = \"truth.txt\"\n",
    "number_of_desired_words = 20\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp']\n",
    "\n",
    "full_text = open(filepath_of_text, encoding=\"utf-8\").read()\n",
    "\n",
    "all_the_words = split_into_words(full_text)\n",
    "meaningful_words = [word for word in all_the_words if word not in stopwords]\n",
    "meaningful_words_tally = Counter(meaningful_words)\n",
    "most_frequent_meaningful_words = meaningful_words_tally.most_common(number_of_desired_words)\n",
    "\n",
    "most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def split_into_words(any_chunk_of_text):\n",
    "    lowercase_text = any_chunk_of_text.lower()\n",
    "    split_words = re.split(\"\\W+\", lowercase_text)\n",
    "    return split_words\n",
    "\n",
    "filepath_of_text = \"brown.txt\"\n",
    "number_of_desired_words = 20\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp']\n",
    "\n",
    "full_text = open(filepath_of_text, encoding=\"utf-8\").read()\n",
    "\n",
    "all_the_words = split_into_words(full_text)\n",
    "meaningful_words = [word for word in all_the_words if word not in stopwords]\n",
    "meaningful_words_tally = Counter(meaningful_words)\n",
    "most_frequent_meaningful_words = meaningful_words_tally.most_common(number_of_desired_words)\n",
    "\n",
    "most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the 20 most frequent words for each narrative. In the Markdown cell below, write down **three observations you have about this data.** These might be similarities between the two narratives, differences between the two, or any other patterns or questions you notice based on their word frequency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation 1: Brown has words like cruel, heart, law, government, and soul. All strong words refer to people, while Truth mentions god 128 times which ties to a more holy motive. \n",
    "\n",
    "Observation 2: They almost equally share how often they say master.  \n",
    "\n",
    "Observation 3: Brown talks about slavery, slaves, etc a lot more than Truth does. Truth mentions Isabella 114 times which makes it the fourth most used word. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text files you've used in this homework were not the original text files of these narratives. Instead, they've been cleaned by your instructor to make them shorter and easier to analyze. Your goal is to use Python to download the original `.txt` files from the website Project Gutenberg. Adapt the code from [these examples](https://python.omics.wiki/www/download-webpage) and use Python's `urllib` package to download the narratives and save them as local files named `truth-original.txt` and `brown-original.txt`.\n",
    "\n",
    "Here are the URL's for the two original text files on Project Gutenberg:\n",
    "\n",
    "- Truth's narrative: <https://www.gutenberg.org/cache/epub/1674/pg1674.txt>\n",
    "- Brown's narrative: <https://www.gutenberg.org/cache/epub/64992/pg64992.txt>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code for the following:\n",
    "\n",
    "- Open and read each of the new text files you just downloaded.\n",
    "- Print out the **number of lines** in each of the original (newly downloaded) text files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the length of the original text files you just downloaded to the cleaned text files you used for the rest of the homework, measured by the number of lines.\n",
    "\n",
    "Write two print() statements that calculate **how many lines were removed by the instructor for each narrative.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What sort of text did the instructor remove? Write Python code that allows you to compare the two versions Sojourner Truth's narrative. Then write a few sentences in the empty Markdown cell below explaining what you found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Write your explanation here_**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
